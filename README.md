# Text generator trained on research notes
## What
I fine-tuned a pre-trained small GPT-2 on my digital research notes, most of which are about neuroscience or machine learning. The dataset (my notes) are not uploaded, but the results and the code is. So, if you have your own dataset to fine-tune to, you can just reuse the notebook. 

I used the open source [huggingface transformers library](https://github.com/huggingface/transformers) and made trivial modifications to this [example fine-tuning notebook](https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb).

## Results
The full results are in `generated_sentences.txt`, and below are some of the more interesting results. The provided prompt is in **bold**. The non-bolded text is autogenerated. 

### Philosophical
**The universe is** full of surprises, unexpected sources of instability.

**The universe is** a good place to store billions of small-world observations

**The universe is** full of interconnected stories

**Math is** another good approximation of the truth, but I don't have any way of making this simple yet, and Math is still useful for complex functions

**Science is** probably the single most important thing to do if we aim at making tech policy.

**Science is** a discovery pipeline that spans across a human-readable medium.

**The world is** full of interconnected datasets. More data can readily fits within a single-dimensional datasphere, but requires more interneuron interactions, more interconnected datasets.

### Brainstorming
**What is the next big thing?** A neural network analysis framework for finding AIZ structured data, where the question is "how to find neurons"

**What is the next big thing?** The next big thing: A categorization of what's going to happen next. A hierarchy of stuff.

### Poetic
**The universe is** full.

Spike, worm, worm, small, big, worm, larger than expected

Spike, worm, smaller than expected

Spike, worm, larger than expected

### Sensible
**The brain is** a small set of interconnected network that constantly changing digital mosaic of neurons; the behavioral data is highly interconnected

**I like** XML - good fit. I like ML for ML for structured presentations.

**I like** your formulation. It's a summary of the definition of semantic terms.

### Mathy
**The number of neurons in the brain is** the ratio of the 1 to the number of N/1. This constant is expressed as the log n+1.

### Fake URLs
**Science is** probably the most active journal in the tech community by far. https://manipulation.google.com/document/d/10.10.136506/attribution-google.com/document/d/6f01

**Information should be** used as a guide to decision making with regards to software development - https://docs.google.com/document.google.com/d/12.google.com/document/d/a0f49f4949.

**I like** digging deep into frameworks and diving. https://docs.google.com/accelerate.com/adamio.com/#/adamio.com/d/1Q2a0GIFjEi0G

